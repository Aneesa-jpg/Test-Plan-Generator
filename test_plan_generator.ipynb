{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb723dff-adf1-44c0-aaee-993d3eb0f8d4",
   "metadata": {},
   "source": [
    "## Test Plan Generator \n",
    "\n",
    "* This project reads the Functional specification document in .pdf, .txt and .docx format and generates a comprehensive Test Plan.\n",
    "* Built using Python and Gradio.\n",
    "\n",
    "### Setup Instructions:\n",
    "\n",
    "Create the environment: \n",
    "\n",
    "* conda env create -f environment.yaml\n",
    "* conda activate test-plan-generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7593ec4-e015-4b87-9fd3-f0c6560f03e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "import pdfplumber\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import tempfile\n",
    "from fpdf import FPDF\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d61c15-5951-4eb0-9720-162bfe4c9c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6978fde7-9576-4db1-ac58-c729c3c82e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileParser:\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        self.filename = os.path.splitext(file)[0].lower()\n",
    "        self.file_extn = os.path.splitext(file)[1].lower()\n",
    "\n",
    "    def extract_text(self):\n",
    "        if self.file_extn == \".txt\":\n",
    "            with open(self.file.name, \"r\", encoding=\"utf-8\") as f:\n",
    "                return f.read()\n",
    "        elif self.file_extn == \".pdf\":\n",
    "            with pdfplumber.open(self.file) as pdf:\n",
    "                return \"\\n\".join(page.extract_text() or \"\" for page in pdf.pages)\n",
    "        elif self.file_extn == \".docx\":\n",
    "            document = Document(self.file)\n",
    "            return \"\\n\".join(para.text for para in document.paragraphs)\n",
    "        else:\n",
    "            raise ValueError (f\"Unsupported file format: {self.file_ext}. Please upload the file in .txt, .pdf, or .docx format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18905cc0-f517-4f0a-be1a-051e9955de1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestPlanGenerator:\n",
    "    def __init__(self, model=\"gpt-4o-mini\"):\n",
    "        self.model = model\n",
    "    \n",
    "    def generate_prompts(self, spec_txt):\n",
    "        system_prompt = \"\"\"\n",
    "        You are a senior QA engineer with deep expertise in analyzing functional specification documents and designing comprehensive test plans.\n",
    "        \n",
    "        When given a functional specification, your job is to:\n",
    "        - Summarize the specification clearly under \"Description\" section.\n",
    "        - State the test plan's goals under \"Objective\" section.\n",
    "        - Identify all functional test cases and present them in a structured format as given below:\n",
    "        \n",
    "          Test Case Format:\n",
    "            - Test Case ID: TC-XXX\n",
    "              Title: [Brief title of the Test Case, eg: Verify user registration with email missing domain name]\n",
    "              Description: [What this test case is intended to verify]\n",
    "              Steps:\n",
    "                1. [Step 1]\n",
    "                2. [Step 2]\n",
    "                ...\n",
    "              Expected Result: [What should happen if the functionality works correctly]\n",
    "        \n",
    "        Follow this format strictly and ensure clarity, correctness, and full test coverage of the provided functional specification. \n",
    "        If the specification document is empty, clearly state that no test plan can be generated.\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        user_prompt = f\"\"\"\n",
    "        Please analyze the following functional specification and generate a detailed test plan in the specified format:\n",
    "        Functional Specification:\n",
    "        \\\"\\\"\\\"\n",
    "        {spec_txt}\n",
    "        \\\"\\\"\\\"\n",
    "        1. **Description**: A brief summary of the functional specification.\n",
    "        2. **Objective**: The purpose and scope of the test plan.\n",
    "        3. **Test Cases**: A list of functional test cases, each including:\n",
    "            - **Test Case ID**: (e.g., TC-001, TC-002...)\n",
    "            - **Title**: A short title describing the test case.\n",
    "            - **Description**: What this test case is intended to verify.\n",
    "            - **Steps**:\n",
    "                1. Step one\n",
    "                2. Step two\n",
    "                ...\n",
    "            - **Expected Result**: The expected behavior or outcome if the functionality works as intended.\n",
    "        \n",
    "        Ensure clarity and full functional coverage. Format the output clearly.\n",
    "        \"\"\"\n",
    "        return system_prompt, user_prompt\n",
    "    \n",
    "    def generate_test_plan(self, spec_txt):\n",
    "        system_prompt, user_prompt = self.generate_prompts(spec_txt)\n",
    "        messages = [\n",
    "            {\"role\" : \"system\" , \"content\" : system_prompt},\n",
    "            {\"role\" : \"user\" , \"content\" : user_prompt}\n",
    "        ]\n",
    "        try: \n",
    "            response = openai.chat.completions.create(\n",
    "                model = self.model,\n",
    "                messages = messages,\n",
    "                temperature = 0.3,\n",
    "                max_tokens = 1500,\n",
    "                stream= True\n",
    "            )\n",
    "            for chunk in response:\n",
    "                result = chunk.choices[0].delta.content or ''\n",
    "                yield result  \n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"LLM Error: \\n{e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfcf69c-77de-4a49-8f79-56385a554eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserAppInterface:\n",
    "    def __init__(self):\n",
    "        self.testplan_generator = TestPlanGenerator()\n",
    "    \n",
    "    def generate_tp_file(self, file, output_format):\n",
    "        try:\n",
    "            parser = FileParser(file)\n",
    "            spec_txt = parser.extract_text()\n",
    "            test_plan = \"\"\n",
    "            response = self.testplan_generator.generate_test_plan(spec_txt)\n",
    "            for chunk in response:\n",
    "                test_plan += chunk\n",
    "                yield test_plan, None\n",
    "\n",
    "            tp_name = parser.filename\n",
    "            tp_extn = output_format.lstrip(\".\").lower()\n",
    "            tp_path = os.path.join(tempfile.gettempdir(), f\"{tp_name}.{tp_extn}\")\n",
    "            if tp_extn == \"txt\":\n",
    "                with open(tp_path, 'w', encoding=\"utf-8\") as f:\n",
    "                    f.write(test_plan)\n",
    "            elif tp_extn == \"pdf\":\n",
    "                pdf = FPDF()\n",
    "                pdf.add_page()\n",
    "                pdf.set_auto_page_break(auto=True, margin=15)\n",
    "                pdf.set_font(\"Arial\", size=12)\n",
    "                for line in test_plan.split('\\n'):\n",
    "                    pdf.multi_cell(0, 10, txt=line)\n",
    "                pdf.output(tp_path)\n",
    "            elif tp_extn == \"docx\":\n",
    "                document = Document()\n",
    "                document.add_heading('Test plan', 0)\n",
    "                for line in test_plan.split('\\n'):\n",
    "                    document.add_paragraph(line)\n",
    "                document.save(tp_path)\n",
    "            else:\n",
    "                return f\"Unsupported file format {tp_extn}\"\n",
    "            yield test_plan, tp_path\n",
    "        \n",
    "        except Exception as e:\n",
    "            yield  f\"Error: {e}\", None\n",
    "\n",
    "    def launch_ui(self):\n",
    "        gr.Interface(fn=self.generate_tp_file,\n",
    "                     inputs=[\n",
    "                         gr.File(label=\"Please upload the Functional Specification file in .txt, .pdf or .docx format\"),\n",
    "                         gr.Dropdown(choices=[\".pdf\", \".txt\", \".docx\"], value=\".txt\", label=\"Please choose the file format\")\n",
    "                     ],\n",
    "                     outputs=[\n",
    "                        gr.Textbox(autoscroll=True, show_copy_button=True, lines=20, label=\"Test Plan:\"),\n",
    "                        gr.File(label=\"Download:\")\n",
    "                     ],\n",
    "                     title=\"Test Plan Generator:\").launch()   \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb069f6f-fe86-4da2-a5b5-bf51fec2b749",
   "metadata": {},
   "outputs": [],
   "source": [
    "UserAppInterface().launch_ui()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
